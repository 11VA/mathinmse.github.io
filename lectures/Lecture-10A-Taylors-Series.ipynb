{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Run these three cells before lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# You can change the default figure size to be a bit larger if you want,\n",
    "# uncomment the next line for that:\n",
    "plt.rc('figure', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_taylor_approximations(func, x0=None, orders=(2, 4), xrange=(0,1), yrange=None, npts=200):\n",
    "    \"\"\"Plot the Taylor series approximations to a function at various orders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : a sympy function\n",
    "    x0 : float\n",
    "      Origin of the Taylor series expansion.  If not given, x0=xrange[0].\n",
    "    orders : list\n",
    "      List of integers with the orders of Taylor series to show.  Default is (2, 4).\n",
    "    xrange : 2-tuple or array.\n",
    "      Either an (xmin, xmax) tuple indicating the x range for the plot (default is (0, 1)),\n",
    "      or the actual array of values to use.\n",
    "    yrange : 2-tuple\n",
    "      (ymin, ymax) tuple indicating the y range for the plot.  If not given,\n",
    "      the full range of values will be automatically used. \n",
    "    npts : int\n",
    "      Number of points to sample the x range with.  Default is 200.\n",
    "    \"\"\"\n",
    "    if not callable(func):\n",
    "        raise ValueError('func must be callable')\n",
    "    if isinstance(xrange, (list, tuple)):\n",
    "        x = np.linspace(float(xrange[0]), float(xrange[1]), npts)\n",
    "    else:\n",
    "        x = xrange\n",
    "    if x0 is None: x0 = x[0]\n",
    "    xs = sp.Symbol('x')\n",
    "    # Make a numpy-callable form of the original function for plotting\n",
    "    fx = func(xs)\n",
    "    f = sp.lambdify(xs, fx, modules=['numpy'])\n",
    "    # We could use latex(fx) instead of str(), but matploblib gets confused\n",
    "    # with some of the (valid) latex constructs sympy emits.  So we play it safe.\n",
    "    plt.plot(x, f(x), label=str(fx), lw=2)\n",
    "    # Build the Taylor approximations, plotting as we go\n",
    "    apps = {}\n",
    "    for order in orders:\n",
    "        app = fx.series(xs, x0, n=order).removeO()\n",
    "        apps[order] = app\n",
    "        # Must be careful here: if the approximation is a constant, we can't\n",
    "        # blindly use lambdify as it won't do the right thing.  In that case, \n",
    "        # evaluate the number as a float and fill the y array with that value.\n",
    "        if isinstance(app, sp.numbers.Number):\n",
    "            y = np.zeros_like(x)\n",
    "            y.fill(app.evalf())\n",
    "        else:\n",
    "            fa = sp.lambdify(xs, app, modules=['numpy'])\n",
    "            y = fa(x)\n",
    "        tex = sp.latex(app).replace('$', '')\n",
    "        plt.plot(x, y, label=r'$n=%s:\\, %s$' % (order, tex) )\n",
    "        \n",
    "    # Plot refinements\n",
    "    if yrange is not None:\n",
    "        plt.ylim(*yrange)\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best').get_frame().set_alpha(0.8)\n",
    "    \n",
    "# For an expression made from elementary functions, we must first make it into\n",
    "# a callable function, the simplest way is to use the Python lambda construct.\n",
    "# plot_taylor_approximations(lambda x: 1/sp.cos(x), 0, [2,4,6,8], (0, 2*sp.pi), (-5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 10:  Taylor's Series and Discrete Calculus\n",
    "\n",
    "### Sections\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Learning Goals](#Learning-Goals)\n",
    "* [On Your Own](#On-Your-Own)\n",
    "    * Deriving Taylor's Series and Helpful Functions\n",
    "    * Visualizing Taylor's Series (Add code above)\n",
    "* [In Class](#In-Class)\n",
    "    * Computing Derivatives of Discrete Data\n",
    "    * Symbolically Computing Forward and Backward Differences\n",
    "* [Homework](#Homework)\n",
    "* [Summary](#Summary)\n",
    "* [Looking Ahead](#Looking-Ahead)\n",
    "* [Reading Assignments and Practice](#Reading-Assignments-and-Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "-----\n",
    "\n",
    "As described by Hornbeck in his introductory text Numerical Methods:  \"The Taylor series is the foundation of numerical methods.\"\n",
    "\n",
    "At this point we have demonstrated how Python (and other languages, I promise!) can help us work out products of matrices.  The benefit is in the way the software helps us avoid silly algebra errors.  Further, we have been able to use the software to solve linear algebra problems.  In this lecture we synthesize the previous two concepts with Taylor series to see how the large majority of modeling in diffusive systems is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_taylor_approximations(sp.sin, 0, [2, 4, 6, 8], (0, 2*sp.pi), (-2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "----\n",
    "\n",
    "1. Become reacquainted with the Taylor series.\n",
    "1. Use the Taylor series to approximate functions and derivatives of discrete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Your Own\n",
    "----\n",
    "\n",
    "### Deriving Taylor's Series and Helpful Functions\n",
    "\n",
    "The function $f(x)$ will be expanded into an infinite series or a finite series plus an error term.  Assume that the function has a continuous nth derivative over the interval $a \\le x \\le b$.  You proceed by integrating the nth derivative n times:\n",
    "\n",
    "$$\\int_a^x f^n(x) dx = f^{(n-1)}(x) - f^{(n-1)}(a)$$\n",
    "\n",
    "and so on ...  Do this n time and then solve for f(x) to recover Taylor's series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key features in this derivation is that the integral is definite.  If the above looks strange, remeber the n is the order of differentiation, not an exponent.  This derivation is outlined on [Wolfram’s Mathworld](http://mathworld.wolfram.com/TaylorSeries.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give us a more concrete feel for what we are doing, we are going to start differently.  Say that we wish to expand sin(x) about x=0.  First, assume that the series exists and can be written as a power series with unknown coefficients.  Differentiate the series and the function we are expanding.  Let the value of x go to the value of the expansion point and then you will get the coefficients in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "sp.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, A, B, C, D, E = sp.symbols('x, A, B, C, D, E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us get our work done we can use `sympy`'s `diff` function.  Of course, you can read the documentation, but, the gist of things is that you pass a symbolic expression and the symbol for the variable you wish to differentiate with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.diff(sp.sin(x),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that $\\sin x$ can be represented in a power series such as $A+Bx+Cx^2+Dx^3+Ex^4$.  How can we figure out the values of ${A,B, C, D, E}$?  We can choose an expansion point (e.g. $x = 0$) and differentiate to get the coefficients.  I do this below in a few lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a list comprehension to organize our results.  Refer back to the Python tutorials we completed if you forgot how to construct such a list.  The first element of the list is the function we want to approximate.  The second element is the power series.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "powerSeries = A+B*x+C*x**2+D*x**3+E*x**4\n",
    "funcAndSeries = [sp.diff(a,x) for a in [sp.sin(x),powerSeries]]\n",
    "funcAndSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you wanted to do all of this in one line you could do the following and using the Matrix class for ease of vewing (and other matrix functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.Matrix([[sp.diff(a,x,i) for a in [sp.sin(x),powerSeries]] for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you allow a substitution where $x=0$ you can solve for the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.Matrix([[sp.diff(a,x,i).subs(x,0) for a in [sp.sin(x),powerSeries]] for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there practical utility in doing this?  Well - as I wrote the above line I had already tested the results on the first three coefficients.  So - I got the last two for \"free\" when I finished coding the above line.  At this point what I'd probably do is functionalize and generalize the code to make a really powerful function.  For example write a function that takes any general function and differentiates it.  I'd also probably make the power series arbitrarily long - so I'd make the maximum power an input.  \n",
    "\n",
    "However, much of this has already been done in Sympy.  See the series() function in Sympy.  To access the documentation use SHIFT-TAB to bring up the help pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.series(sp.sin(x), x, x0=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an expression without the trailing descriptor (that indicates what order of terms are omitted) use the .removeO() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.series(sp.sin(x), x, x0=0).removeO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the comparision of the coefficients to your hand calculation!  The above is really the long way around..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for i in numbers:\n",
    "    np.sin(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for i in numbers:\n",
    "    i*i*i*i*i/120. - i*i*i/6. + i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY:  Compute a power series for an exponential function.\n",
    "\n",
    "You just acquired some important knowledge for how to construct a series using Python.  Apply that knowledge to construct a series representation for the function $\\exp(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY:  How good is the small angle approximation?\n",
    "\n",
    "In electron microscopy you often use the trigonometric function $\\tan()$.  Diffraction geometry is such that the angles are very small, therefore, the approximation is often made that $\\tan(2\\theta)=2\\theta$.  What is the error associated with this approximation in powers of the angle? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY:  Construct a Taylor series Symbolically\n",
    "\n",
    "Sometimes symbolic construction of a series is helpful.  Using an arbitrary function $f$, expand $f$ in $x$ about $h$.  You will need to use Sympy's \"Function\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sympy import init_printing, symbols, Function\n",
    "init_printing()\n",
    "\n",
    "x, h = symbols(\"x,h\")\n",
    "f = Function(\"f\")\n",
    "\n",
    "f(x).series(x, x0=h, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small bug in the Sympy printer (that comes as part of the Canopy distribution) that misses a space between the $x \\rightarrow h$ above.  You can print to LaTeX and fix it yourself in the notebook if you find it distracting.  See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sympy import series, latex\n",
    "print(latex(series(f(x), x, x0=h, n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer with the whitespace correction should read:  \n",
    "\n",
    "$$f{\\left (h \\right )} + \\left(- h + x\\right) \\left. \\frac{d}{d \\xi_{1}} f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=h }} + \\frac{1}{2} \\left(- h + x\\right)^{2} \\left. \\frac{d^{2}}{d \\xi_{1}^{2}}  f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=h }} + \\mathcal{O}\\left(\\left(- h + x\\right)^{3}; x\\rightarrow h\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Class\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Derivatives of Discrete Data\n",
    "\n",
    "When you have a function that is differentible then it can be straightforward to compute it's derivative.  For example:\n",
    "\n",
    "$$f(x) = x^2$$\n",
    "$$f'(x) = 2x$$\n",
    "\n",
    "What do I mean when I say discrete data?  In abstract terms I mean a list of values that is dependent on some other variable (like $x$):\n",
    "\n",
    "$$\\{f(x_0), f(x_1), f(x_2), ...\\}$$\n",
    "\n",
    "This list could be the numerical representation of anything.  This is a key point - the data are only numbers.  There is no known function (you may come to know it later, though) that relates the numbers.  Imagine collecting temperatures over time, or measuring the height of a series of parts, etc.\n",
    "\n",
    "Let's say you collected some data, but your models relate the derivative quantities of the data.  What can you do to approximate the derivatives?  We have an unknown functional form.  Here is where Taylor's series comes in handy.  We are going to compute a series expansion for an unknown function $f(x)$ and then examine the relationship between that function and it's derivative quantities at a point $h$ nearby.  The goal of the activity is to see if we can find expressions for the derivatives using the data point of interest and its neighbors.  We are going to use the idea of _forward_ and _backward_ differences.\n",
    "\n",
    "1. Forward differences are computed by expanding an unknown function in a Taylor series about a point “c” and then letting x go to c+h.\n",
    "1. Backward differences let x go to c-h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolically Computing Forward and Backward Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that we take the above series expansion and use it to compute the value of the function near the point $c$.  Let us move by an amount $h$ to the left and right.  We write down the series expansion for our function about the point “c” at a value of x that equals c+h and c-h. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember how to substitute values for symbols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, h, c = sp.symbols(\"x,h,c\")\n",
    "f = sp.Function(\"f\")\n",
    "\n",
    "taylorExpansionPlus = f(x).series(x, x0=c, n=3).removeO().subs(x,c+h)\n",
    "taylorExpansionMinus = f(x).series(x, x0=c, n=3).removeO().subs(x,c-h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taylorExpansionPlus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning that:\n",
    "\n",
    "$$\n",
    "f(c+h) = \\frac{h^{2}}{2} \\left. \\frac{d^{2}}{d \\xi_{1}^{2}}  f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} + h \\left. \\frac{d}{d \\xi_{1}} f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} + f{\\left (c \\right )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taylorExpansionMinus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning that:\n",
    "\n",
    "$$\n",
    "f(c-h) = \\frac{h^{2}}{2} \\left. \\frac{d^{2}}{d \\xi_{1}^{2}}  f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} - h \\left. \\frac{d}{d \\xi_{1}} f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} + f{\\left (c \\right )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for First and Second Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can change the addition or subtraction of the two finite difference expressions to see what terms remain.  Note that each grouped expression is equal to zero.  This is assumed in Sympy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(taylorExpansionMinus-f(c-h))-(taylorExpansionPlus-f(c+h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `sympy` expressions are zero by default.  So this is true:\n",
    "\n",
    "$$\n",
    "- 2 h \\left. \\frac{d}{d \\xi_{1}} f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} - f{\\left (c - h \\right )} + f{\\left (c + h \\right )} = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(taylorExpansionMinus-f(c-h))+(taylorExpansionPlus-f(c+h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly:\n",
    "\n",
    "$$\n",
    "h^{2} \\left. \\frac{d^{2}}{d \\xi_{1}^{2}}  f{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=c }} + 2 f{\\left (c \\right )} - f{\\left (c - h \\right )} - f{\\left (c + h \\right )} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the core definitions of the finite difference calculus.  I wonder how you could produce the third and fourth derivatives?  (nudge nudge, wink wink...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY:  Discrete Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a list (grid) of data from a function such as $\\sin(x)$ over the range $0$ to $2\\pi$.\n",
    "* Compute the derivative(s) analytically by differentiating $\\sin(x)$.\n",
    "* Compute the first and second derivative(s) using finite differences between $0$ and $2\\pi$ from a list of discrete points and plot the error between the analytical derivative and your numerical approximation as a function of the resolution of the grid.\n",
    "* Produce a visualization and a figure caption that captures a particular piece of knowledge you gained as part of this assignment.\n",
    "\n",
    "Knowledge of some useful tools will help here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print np.arange.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example set of grid points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(0,2*np.pi,np.pi/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY:  Vectorized Computations\n",
    "\n",
    "A _list_ is one of the fundamental data structures within Python.  Numpy (a Python library) and other parts of Python libraries use _vectorized_ computations.  From Wikipedia, vectorization is \"a style of computer programming where operations are applied to whole arrays instead of individual elements.\"  \n",
    "\n",
    "With this in mind, we certainly _can_ iterate over our list of points and apply the function that you will soon write in an element by element fashion, however, it is a more common practice in Python and other modern languages to write vectorized code.  If this is your first exposure to vectorized computation, I recommend two initial strategies:\n",
    "\n",
    "1.  Write out your algorithms, and\n",
    "1.  Use \"classic\" flow control and iteration to compute the results.\n",
    "\n",
    "From that point you will more easily see the strategy you should use to write vectorized code.  \n",
    "\n",
    "* Using the discrete forms of the first and second derivatives (based on central differences) can you devise a vectorized operation that computes the derivative without looping in Python?\n",
    "\n",
    "The following code snippets are a hint.  If you don't see the solution right away - write out your derivatives for each element of the array explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aList = np.arange(0,2*np.pi,np.pi/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aList[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aList[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aList[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "----\n",
    "\n",
    "1.  Derive the expression for the numerical approximation of the Laplacian (second derivative) in two dimensions using the appropriate definition for Taylor's series.  Some additional reading will help you do this.  Compute the analytical and numerical Laplacian for the function $f(x,y)=x^2y^2$ on a grid with spacing $\\Delta x$ and $\\Delta y$.  Compare the discrete calculation to the analytical calculation.\n",
    " \n",
    "1.  Using what you’ve learned thus far, write down the discrete form of Fick’s law in one dimension.  Assume the data that represents compositions for any particular time is given in a list.  (Do you need to remind yourself what Fick’s law is?)  Hint: consider that you should forward difference in time and central difference in space.  Have a look at the pages in Hornbeck that are available on the wiki.\n",
    "\n",
    "_N.B. the second part of the assignment is not difficult.  What will be challenging for you is to relate the knowledge you've gained as part of this assignment to the bigger picture of diffusion in materials.  This gap between your current state of knowledge and where I'm leading you (in problem 2) is intentional.  I would like you to discover something on your own - so I'm pointing you in a particular direction and asking you to \"explore\" and synthesize the information you have into something bigger!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "----\n",
    "\n",
    "1.  In `sympy` Taylor's series can be used to approximate functions near a point “a”.  They are constructed using the series() function.\n",
    "1.  Discrete data can be used in conjunction with the Taylor series to compute derivatives when no analytical form is available.\n",
    "1.  The Taylor series is used as the basis for many tasks in numerical computing so mastery of this concept, knowledge and application of Taylor's series both analytically and numerically is absolutely essential.\n",
    "1.  The last bullet point is important.  Read it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Ahead\n",
    "----\n",
    "\n",
    "* We will be reviewing how to perform vector calculus.  \n",
    "* Concepts of fields and vector fields will be introduced.\n",
    "* These will be important for describing differential equations in real materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Assignments and Practice\n",
    "----\n",
    "\n",
    "* Schaum's handbook of mathematical tables has tables of series definitions for transcendental functions.  Our library has a digital copy that you can \"check out\".  Why not compare what `sympy` returns with what is listed in the tables?\n",
    "* Building confidence in `sympy`'s performance is a good thing!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
